{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNiuEarPwtTCVmLxakxh1N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YousefAbua/Intro-To-ML/blob/main/Homework5/CtoF_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "1xuZMJUXOiHm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)"
      ],
      "metadata": {
        "id": "rBr9oD06QKsC"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(t_u, w1, w2, b):\n",
        "  return w2*t_u**2 + w1*t_u + b"
      ],
      "metadata": {
        "id": "VXJjNswOQskH"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c)**2\n",
        "  return squared_diffs.mean()\n"
      ],
      "metadata": {
        "id": "5EpvTlO4Q3k5"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(n_epochs, optimizer, learning_rate, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()\n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      params -= learning_rate * params.grad\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
        "\n",
        "  return params"
      ],
      "metadata": {
        "id": "Iwg6_0jcgB-d"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 0.1\n",
        "t_un = 0.01 * t_u\n",
        "optimizer = torch.optim.Adam([params], lr=learning_rate)\n",
        "print('Learning Rate: ', learning_rate)\n",
        "training_loop(5000, optimizer, learning_rate, params, t_un, t_c)\n",
        "\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 0.01\n",
        "print('\\n\\nLearning Rate: ', learning_rate)\n",
        "training_loop(5000, optimizer, learning_rate, params, t_un, t_c)\n",
        "\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 0.001\n",
        "print('\\n\\nLearning Rate: ', learning_rate)\n",
        "training_loop(5000, optimizer, learning_rate, params, t_un, t_c)\n",
        "\n",
        "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 0.0001\n",
        "print('\\n\\nLearning Rate: ', learning_rate)\n",
        "training_loop(5000, optimizer, learning_rate, params, t_un, t_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLUHjGT4g2KS",
        "outputId": "95a48c19-8e9a-4b91-9653-51c0e8dd3a1a"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate:  0.1\n",
            "Epoch 500, Loss 2.108455\n",
            "Epoch 1000, Loss 2.090726\n",
            "Epoch 1500, Loss 2.090720\n",
            "Epoch 2000, Loss 2.090720\n",
            "Epoch 2500, Loss 2.090721\n",
            "Epoch 3000, Loss 2.090719\n",
            "Epoch 3500, Loss 2.090720\n",
            "Epoch 4000, Loss 2.090720\n",
            "Epoch 4500, Loss 2.090720\n",
            "Epoch 5000, Loss 2.090720\n",
            "\n",
            "\n",
            "Learning Rate:  0.01\n",
            "Epoch 500, Loss 26.266182\n",
            "Epoch 1000, Loss 12.949668\n",
            "Epoch 1500, Loss 6.968258\n",
            "Epoch 2000, Loss 4.281574\n",
            "Epoch 2500, Loss 3.074787\n",
            "Epoch 3000, Loss 2.532740\n",
            "Epoch 3500, Loss 2.289264\n",
            "Epoch 4000, Loss 2.179901\n",
            "Epoch 4500, Loss 2.130778\n",
            "Epoch 5000, Loss 2.108713\n",
            "\n",
            "\n",
            "Learning Rate:  0.001\n",
            "Epoch 500, Loss 58.822189\n",
            "Epoch 1000, Loss 48.348244\n",
            "Epoch 1500, Loss 44.396774\n",
            "Epoch 2000, Loss 41.118404\n",
            "Epoch 2500, Loss 38.115963\n",
            "Epoch 3000, Loss 35.345898\n",
            "Epoch 3500, Loss 32.788925\n",
            "Epoch 4000, Loss 30.428560\n",
            "Epoch 4500, Loss 28.249681\n",
            "Epoch 5000, Loss 26.238342\n",
            "\n",
            "\n",
            "Learning Rate:  0.0001\n",
            "Epoch 500, Loss 138.825058\n",
            "Epoch 1000, Loss 118.428955\n",
            "Epoch 1500, Loss 102.817139\n",
            "Epoch 2000, Loss 90.845161\n",
            "Epoch 2500, Loss 81.642403\n",
            "Epoch 3000, Loss 74.546761\n",
            "Epoch 3500, Loss 69.054512\n",
            "Epoch 4000, Loss 64.782639\n",
            "Epoch 4500, Loss 61.439713\n",
            "Epoch 5000, Loss 58.804115\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.8014, 3.7440, 4.9612], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3uY3Q_VhNc9"
      },
      "execution_count": 182,
      "outputs": []
    }
  ]
}